{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKx3VPzmBHSf"
      },
      "source": [
        "# <center>**ProBASS: a language model with sequence and structural features for predicting the effect of mutations on binding affinity**</center>\n",
        "---\n",
        "Here we introduce a model (ProBASS) which is fine-tuned, incorporating features derived from both Protein Language models ESM-2 and ESM-IF1.This model is designed for the prediction of ddGbind values, which serve as indicators of both the sequence and structural attributes of the mutated protein complexes.\n",
        "\n",
        "The model is an efficient way to predict the effect of mutations on protein binding affinity.\n",
        "\n",
        "---\n",
        "\n",
        "**Instructions for users on how to provide the PDB ID of the protein complex and the CSV file which contains the mutation information to Probass**\n",
        "\n",
        "Please input the \"PDB ID\" of the Protein complex under the subcategory Input Data which is required to calculate the binding affinity of the mutations.\n",
        "\n",
        "The user can specify the desired mutations for binding affinity calculation by providing the information in a CSV file named 'Input.csv'. This file should include five columns as below with the following headers: 'Mutated_chain', 'Partner_chain', 'Wild_type', 'Position', and 'Mutation'. Once the desired PDB ID is specified, the 'Choose File' button will automatically appear after running the notebook, allowing you to upload the 'Input.csv' file.\n",
        "\n",
        "The 'Mutated_chain' and 'Partner_chain' define the interface of the protein complex. 'Wild_type' refers to the original amino acid in the protein complex, 'Position' indicates the location of the desired mutation, and 'Mutation' specifies the amino acid the user wishes to substitute for the wild type. A sample \"Input.csv\" file can be downloaded from the following link : https://github.com/sagagugit/ProBASS/blob/main/examples/Input.csv\n",
        "\n",
        "Warning: Please upload no more than 150 mutations at a time.\n",
        "\n",
        "![](https://github.com/sagagugit/ProBASS/blob/main/examples/Input_picture.png?raw=true)\n",
        "\n",
        "You can also download a sample input file titled \"Input.csv\" from the GitHub page.\n",
        "\n",
        "**Instructions for using this Colab notebook**\n",
        "\n",
        "Two options are possible for uploading the protein complex structure.\n",
        "\n",
        "1)\t**The complex structure is downloaded directly from the PDB**. Please input the \"PDB ID\" of the Protein complex.\n",
        "\n",
        "\n",
        "2)\t**The complex structure is uploaded from the userâ€™s computer**. To enable users to upload their own complex, kindly remove the comment symbols (#) from all lines in the section labeled \"Uploading the complex instead of PDB ID\". Once uncommented, the user can upload their desired complex upon execution. **Before execution of the program**, The file that you are uploading should be named as a pdb file: 4 letter code with a pdb extension (for example, 3OTJ.pdb). The same pdb file should be specified below under PDB ID."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3k0uM_5fN9K"
      },
      "source": [
        "# Environment Set up for **ProBASS:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ngtlA-3ygDxe"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install torch-geometric\n",
        "!pip install biotite==0.33.0\n",
        "!pip install catboost\n",
        "!pip install git+https://github.com/facebookresearch/esm.git\n",
        "!pip install requests\n",
        "!pip install biopython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I_kHuX4TspGw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import catboost as cb\n",
        "import torch\n",
        "import esm\n",
        "import scipy\n",
        "from numpy import asarray\n",
        "from numpy import savez_compressed\n",
        "import requests\n",
        "from Bio.PDB import PDBParser"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "cd /content/\n",
        "\n",
        "if [ ! -f ProBASS ]; then\n",
        "\n",
        "\n",
        "    # delete the Cold-scanner/ directory if it already exists\n",
        "    if [ -d \"ProBASS/\" ]; then\n",
        "        rm -rf ProBASS/\n",
        "    fi\n",
        "\n",
        "    # download model\n",
        "    git clone https://github.com/sagagugit/ProBASS --quiet\n",
        "    touch ProBASS\n",
        "fi"
      ],
      "metadata": {
        "id": "EsfKhaV9plmm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Input Data"
      ],
      "metadata": {
        "id": "slMOUZcHMjcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# from contextlib import redirect_stdout\n",
        "\n",
        "# try:\n",
        "#     from google.colab import drive\n",
        "\n",
        "#     with redirect_stdout(open(os.devnull, 'w')):\n",
        "#         drive.mount('/content/drive')\n",
        "\n",
        "#     from google.colab import files\n",
        "\n",
        "\n",
        "#     print(\"Please upload the .pdb file\")\n",
        "\n",
        "\n",
        "#     uploaded = files.upload()\n",
        "# except FileNotFoundError:\n",
        "#     print(\"ERROR: \\n Uploading was not successful. Please restart and try to upload the complex again.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "KxVZYrF9gi2p"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CyrX8RlilBx",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title PDB ID\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive, files\n",
        "import contextlib\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "PDB = '3OTJ' #@param {type:\"string\"}\n",
        "\n",
        "pdb_file_path = f'/content/{PDB}.pdb'\n",
        "\n",
        "\n",
        "if os.path.exists(pdb_file_path):\n",
        "\n",
        "    pass\n",
        "else:\n",
        "\n",
        "    display(HTML(\"<h4>Please upload the Input.csv file</h4>\"))\n",
        "\n",
        "    with open(os.devnull, 'w') as devnull, contextlib.redirect_stdout(devnull):\n",
        "        drive.mount('/content/drive')\n",
        "        uploaded = files.upload()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Selecting Path"
      ],
      "metadata": {
        "id": "3b4dxngwJ2QA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%cd ProBASS\n",
        "!cp /content/Input.csv /content/ProBASS"
      ],
      "metadata": {
        "id": "Q647f5cQiqYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IwIHN76la03"
      },
      "source": [
        "# Extracting embeddings from ESM2 and ESM-IF1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRvtBTBxnYUk"
      },
      "source": [
        "# Extracting Fasta files for wild type, partner chain and mutated PPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7uWQFbrnrSX"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "PDB_code = PDB\n",
        "\n",
        "url = f'http://www.rcsb.org/pdb/download/downloadFile.do?fileFormat=pdb&structureId={PDB_code}'\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    with open(f'{PDB_code}.pdb', 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f'{PDB_code}.pdb has been downloaded successfully.')\n",
        "else:\n",
        "    print(f'Failed to download {PDB_code}.pdb. Status code: {response.status_code}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio.PDB import PDBParser\n",
        "import pandas as pd\n",
        "\n",
        "RESIDUE_NAME_TO_LETTER = {\n",
        "    'ALA': 'A', 'ARG': 'R', 'ASN': 'N', 'ASP': 'D', 'CYS': 'C',\n",
        "    'GLU': 'E', 'GLN': 'Q', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I',\n",
        "    'LEU': 'L', 'LYS': 'K', 'MET': 'M', 'PHE': 'F', 'PRO': 'P',\n",
        "    'SER': 'S', 'THR': 'T', 'TRP': 'W', 'TYR': 'Y', 'VAL': 'V'\n",
        "}\n",
        "try:\n",
        "  input_csv = 'Input.csv'\n",
        "  df = pd.read_csv(input_csv)\n",
        "  PDB_code = PDB\n",
        "\n",
        "\n",
        "  pdb_file = f'{PDB_code}.pdb'\n",
        "  parser = PDBParser(QUIET=True)\n",
        "  structure = parser.get_structure(PDB_code, pdb_file)\n",
        "\n",
        "  def extract_sequence_and_start(chain_id):\n",
        "      sequence = []\n",
        "      start_residue_number = None\n",
        "      for model in structure:\n",
        "          for chain in model:\n",
        "              if chain.get_id() == chain_id:\n",
        "                  for residue in chain:\n",
        "                      resname = residue.get_resname()\n",
        "                      resnum = residue.get_id()[1]\n",
        "                      if start_residue_number is None:\n",
        "                          start_residue_number = resnum\n",
        "                      if resname in RESIDUE_NAME_TO_LETTER:\n",
        "                          sequence.append(RESIDUE_NAME_TO_LETTER[resname])\n",
        "      return ''.join(sequence), start_residue_number\n",
        "\n",
        "  def adjust_positions(mutated_chain_id, position):\n",
        "      _, start_residue = extract_sequence_and_start(mutated_chain_id)\n",
        "      return position - start_residue + 1\n",
        "\n",
        "\n",
        "  def apply_mutation(sequence, position, new_residue):\n",
        "      sequence_list = list(sequence)\n",
        "\n",
        "\n",
        "      sequence_list[position - 1] = new_residue\n",
        "      return ''.join(sequence_list)\n",
        "\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "      mutated_chain_id = row['Mutated_chain']\n",
        "      partner_chain_id = row['Partner_chain']\n",
        "      mutation_position = row['Position']\n",
        "      new_residue = row['Mutation']\n",
        "\n",
        "      mutated_sequence, mutated_start_residue = extract_sequence_and_start(mutated_chain_id)\n",
        "      partner_sequence, _ = extract_sequence_and_start(partner_chain_id)\n",
        "\n",
        "\n",
        "      adjusted_position = adjust_positions(mutated_chain_id, mutation_position)\n",
        "      mutated_sequence = apply_mutation(mutated_sequence, adjusted_position, new_residue)\n",
        "      with open(f'{PDB_code}_wild.fasta', 'w') as f:\n",
        "          f.write(f'> {PDB_code}_wild\\n{mutated_sequence}\\n')\n",
        "\n",
        "      with open(f'{PDB_code}_partner.fasta', 'w') as f:\n",
        "          f.write(f'> {PDB_code}_partner\\n{partner_sequence}\\n')\n",
        "except Exception as e:\n",
        "    print(\"\\033[1mERROR MESSAGE:!!!\\033[0m\\nPlease verify that the Input.csv file is properly formatted and that the mutation information is accurate.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "TjpHiKgIjjPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PDB_code = PDB\n",
        "input_csv = 'Input.csv'\n",
        "df = pd.read_csv(input_csv)\n",
        "\n",
        "def read_fasta(fasta_file):\n",
        "    with open(fasta_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    sequence = ''.join(line.strip() for line in lines[1:])\n",
        "    return sequence\n",
        "\n",
        "wild_sequence = read_fasta(f'{PDB_code}_wild.fasta')\n",
        "\n",
        "def extract_residue_numbers(pdb_file, chain_id):\n",
        "    from Bio.PDB import PDBParser\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure(PDB_code, pdb_file)\n",
        "\n",
        "    residue_numbers = []\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            if chain.get_id() == chain_id:\n",
        "                for residue in chain:\n",
        "                    residue_numbers.append(residue.get_id()[1])\n",
        "    return residue_numbers\n",
        "\n",
        "def pdb_position_to_index(pdb_residue_numbers, pdb_position):\n",
        "    try:\n",
        "        return pdb_residue_numbers.index(pdb_position)\n",
        "    except ValueError:\n",
        "        print(f\"Warning: Position {pdb_position} not found in the PDB file.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "mutated_chain_id = df['Mutated_chain'].iloc[0]\n",
        "pdb_residue_numbers = extract_residue_numbers(f'{PDB_code}.pdb', mutated_chain_id)\n",
        "\n",
        "\n",
        "fasta_entries = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    mutated_sequence = list(wild_sequence)\n",
        "    pdb_position = row['Position']\n",
        "    mutation = row['Mutation']\n",
        "\n",
        "    idx = pdb_position_to_index(pdb_residue_numbers, pdb_position)\n",
        "\n",
        "\n",
        "    if idx is not None and 0 <= idx < len(mutated_sequence):\n",
        "        mutated_sequence[idx] = mutation\n",
        "\n",
        "\n",
        "        mutated_sequence_str = ''.join(mutated_sequence)\n",
        "\n",
        "\n",
        "        fasta_header = f'> {PDB_code}_{pdb_position}{mutation}\\n'\n",
        "\n",
        "        fasta_entries.append(fasta_header + mutated_sequence_str + '\\n')\n",
        "\n",
        "with open(f'{PDB_code}.fasta', 'w') as f:\n",
        "    f.writelines(fasta_entries)\n",
        "\n"
      ],
      "metadata": {
        "id": "tMZMuaJXjonO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOspFrP_qUhl"
      },
      "source": [
        "# Extract sequence embeddings and Structural embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEMbn79PqkWj"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "PDB_code = PDB\n",
        "\n",
        "!python extract.py esm2_t33_650M_UR50D {PDB}.fasta {PDB}_esm2 --repr_layers 0 32 33 --include mean per_tok\n",
        "\n",
        "!python extract.py esm2_t33_650M_UR50D {PDB}_wild.fasta {PDB}_esm2_wild --repr_layers 0 32 33 --include mean per_tok\n",
        "\n",
        "!python extract.py esm2_t33_650M_UR50D {PDB}_partner.fasta {PDB}_esm2_partner --repr_layers 0 32 33 --include mean per_tok\n",
        "\n",
        "model, alphabet = esm.pretrained.esm_if1_gvp4_t16_142M_UR50()\n",
        "model = model.eval()\n",
        "\n",
        "fpath = PDB + '.pdb'\n",
        "input_file = 'Input.csv'\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "chain_ids = list(set(df['Mutated_chain'].tolist() + df['Partner_chain'].tolist()))\n",
        "structure = esm.inverse_folding.util.load_structure(fpath, chain_ids)\n",
        "coords, native_seqs = esm.inverse_folding.multichain_util.extract_coords_from_complex(structure)\n",
        "\n",
        "print(f'Loaded chains: {list(coords.keys())}\\n')\n",
        "\n",
        "for chain_id in chain_ids:\n",
        "    print(f'Chain {chain_id} native sequence:')\n",
        "    print(native_seqs[chain_id])\n",
        "    print('\\n')\n",
        "\n",
        "\n",
        "mutated_chain_ids = df['Mutated_chain'].unique()\n",
        "\n",
        "\n",
        "target_chain_id = mutated_chain_ids[0]\n",
        "rep = esm.inverse_folding.multichain_util.get_encoder_output_for_complex(model, alphabet, coords, target_chain_id)\n",
        "len(coords), rep.shape\n",
        "print(len(coords), rep.shape)\n",
        "print(target_chain_id)\n",
        "\n",
        "numpy_rep =rep.detach().numpy()\n",
        "print(numpy_rep)\n",
        "np.savez(f\"inverse_{PDB}.npz\", data=numpy_rep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OagSSYQMrRLK"
      },
      "source": [
        "# Run ProBASS to predict the Î”Î”G values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qa-uEhrrw1V"
      },
      "outputs": [],
      "source": [
        "PDBS = PDB_code = [PDB]\n",
        "\n",
        "def exctracting_embeddings_esm2(pdb):\n",
        "    mutations2= []\n",
        "    Xs2 = []\n",
        "    for header2, _seq2 in esm.data.read_fasta(FASTA_PATH2):\n",
        "        scaled_effect2 = header2.split('|')[-1]\n",
        "        mutations2.append(scaled_effect2)\n",
        "        fn = f'{EMB_PATH2}/{header2[1:]}.pt'\n",
        "        embs2 = torch.load(fn)\n",
        "        Xs2.append(embs2['representations'][33])\n",
        "    Xs2 = torch.stack(Xs2, dim=0).numpy()\n",
        "\n",
        "    return Xs2, mutations2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def exctracting_embeddings_esm2_wild(pdb):\n",
        "    mutations2_w= []\n",
        "    Xs2_w = []\n",
        "    for header2, _seq2 in esm.data.read_fasta(FASTA_PATH2_w):\n",
        "        scaled_effect2_w = header2.split('|')[-1]\n",
        "        mutations2_w.append(scaled_effect2_w)\n",
        "        fn = f'{EMB_PATH2_w}/{header2[1:]}.pt'\n",
        "        embs2 = torch.load(fn)\n",
        "        Xs2_w.append(embs2['representations'][33])\n",
        "    Xs2_w = torch.stack(Xs2_w, dim=0).numpy()\n",
        "\n",
        "    return Xs2_w\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def exctracting_embeddings_esm2_bind(pdb):\n",
        "    mutations2_b= []\n",
        "    Xs2_b = []\n",
        "    for header2, _seq2 in esm.data.read_fasta(FASTA_PATH2_b):\n",
        "        scaled_effect2_b = header2.split('|')[-1]\n",
        "        mutations2_b.append(scaled_effect2_b)\n",
        "        fn = f'{EMB_PATH2_b}/{header2[1:]}.pt'\n",
        "        embs2 = torch.load(fn)\n",
        "        Xs2_b.append(embs2['representations'][33])\n",
        "    Xs2_b = torch.stack(Xs2_b, dim=0).numpy()\n",
        "\n",
        "    return Xs2_b\n",
        "\n",
        "def exctracting_embeddings_1f(pdb):\n",
        "    temp= np.load(inverse_path)\n",
        "    inverse= temp['data']\n",
        "\n",
        "\n",
        "    average_mean_embedding = np.mean(inverse, axis=0)\n",
        "    average_mean_embedding.shape\n",
        "    inverse_mean_reshape = average_mean_embedding.reshape([1, 512])\n",
        "    inverse_mean_reshape.shape\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return inverse_mean_reshape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "ddg_values = []\n",
        "embeddings = []\n",
        "for pdb in PDBS:\n",
        "    FASTA_PATH = \"/content/ProBASS/{}.fasta\".format(pdb)\n",
        "    EMB_PATH = \"/content/ProBASS/{}_1V\".format(pdb)\n",
        "    FASTA_PATH2 = \"/content/ProBASS/{}.fasta\".format(pdb)\n",
        "    EMB_PATH2 = \"/content/ProBASS/{}_esm2\".format(pdb)\n",
        "    FASTA_PATH_w = \"/content/ProBASS/{}_wild.fasta\".format(pdb)\n",
        "    EMB_PATH_w = \"/content/ProBASS/{}_1V_wild\".format(pdb)\n",
        "    FASTA_PATH2_w = \"/content/ProBASS/{}_wild.fasta\".format(pdb)\n",
        "    EMB_PATH2_w = \"/content/ProBASS/{}_esm2_wild\".format(pdb)\n",
        "    FASTA_PATH_b = \"/content/ProBASS/{}_partner.fasta\".format(pdb)\n",
        "    EMB_PATH_b = \"/content/ProBASS/{}_1V_partner\".format(pdb)\n",
        "    FASTA_PATH2_b = \"/content/ProBASS/{}_partner.fasta\".format(pdb)\n",
        "    EMB_PATH2_b = \"/content/ProBASS/{}_esm2_partner\".format(pdb)\n",
        "    inverse_path = '/content/ProBASS/inverse_{}.npz'.format(pdb)\n",
        "    csv_path = \"/content/ProBASS/{}.csv\".format(pdb)\n",
        "    Xs2, mutations2= exctracting_embeddings_esm2(pdb)\n",
        "    Xs2_w= exctracting_embeddings_esm2_wild(pdb)\n",
        "    Xs2_w=np.tile(Xs2_w, (len(Xs2), 1, 1))\n",
        "    Xs2_b=exctracting_embeddings_esm2_bind(pdb)\n",
        "    Xs2_b=np.tile(Xs2_b, (len(Xs2), 1, 1))\n",
        "    inverse=exctracting_embeddings_1f(pdb)\n",
        "    inverse=np.tile(inverse, (len(Xs2), 1))\n",
        "    mutant_and_partner_together_esm2 = np.concatenate([Xs2_b, Xs2], axis =1)\n",
        "\n",
        "    wild_type_and_partner_together_esm2 = np.concatenate([Xs2_b, Xs2_w], axis =1)\n",
        "    mutant_and_partner_together_esm2_mean=np.mean(mutant_and_partner_together_esm2, axis=1)\n",
        "    wild_type_and_partner_together_esm2_mean=np.mean(wild_type_and_partner_together_esm2, axis=1)\n",
        "    ddg_1v = np.subtract(mutant_and_partner_together_esm2_mean, wild_type_and_partner_together_esm2_mean)\n",
        "\n",
        "    ddg_esm2_with_inverse = np.concatenate([ddg_1v, inverse], axis =1)\n",
        "    embeddings.append(ddg_esm2_with_inverse)"
      ],
      "metadata": {
        "id": "8vouJu42j-Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "ddg_length = len(embeddings[0])\n",
        "ddg_values = [0] * ddg_length\n",
        "\n",
        "\n",
        "flattened_list = ddg_values\n",
        "\n",
        "\n",
        "extracted_array = embeddings[0]\n",
        "Xs_test = extracted_array\n",
        "ys_test = flattened_list\n",
        "\n",
        "np.savez('test.npz', data=Xs_test, label=ys_test)"
      ],
      "metadata": {
        "id": "fb0ixxAVkBm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = np.load('test.npz')\n",
        "X_test, test_y = temp['data'], temp['label']"
      ],
      "metadata": {
        "id": "w10iJgAKkDkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load your Input.csv\n",
        "input_data = pd.read_csv('Input.csv')\n",
        "#Load your model and make predictions\n",
        "model = cb.CatBoostRegressor()\n",
        "loaded_model1 = cb.CatBoostRegressor()\n",
        "loaded_model1.load_model('Probass_model.cbm')\n",
        "\n",
        "ypred = loaded_model1.predict(X_test)\n",
        "\n",
        "\n",
        "input_data['Mutation'] = input_data['Wild_type'] + input_data['Position'].astype(str) + input_data['Mutation']\n",
        "\n",
        "predicted_df = pd.DataFrame({'Mutation': input_data['Mutation'], 'predicted_value': ypred})\n",
        "\n",
        "predicted_df.to_csv('predicted_values.csv', index=False)\n"
      ],
      "metadata": {
        "id": "-tCwzqKfkFXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Predicted Binding Affinintes"
      ],
      "metadata": {
        "id": "R9npsnXKnHou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "files.download('predicted_values.csv')"
      ],
      "metadata": {
        "id": "gVtZdV_XnMRI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "I3k0uM_5fN9K",
        "3b4dxngwJ2QA",
        "KRvtBTBxnYUk",
        "oOspFrP_qUhl",
        "OagSSYQMrRLK",
        "R9npsnXKnHou"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}